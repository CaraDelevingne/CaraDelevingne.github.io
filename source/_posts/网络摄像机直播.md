---
title: '网络摄像机直播'
date: 2018-05-06 14:49:04
tags:
- JavaScript
- Node.js
- FFmpeg
categories:
- 笔记📒
---
对于网络摄像机做视频预览这块, 本身其实是非常陌生的, 当时接到这个需求也是相当的头疼(对于当时一年经验不到的我来说).当时我们的应用场景是: 多路网络摄像机通过局域网连接, PC 端能够实时预览监控画面并且画质达到720p, 延迟不能超过10秒, 多个摄像机能够切换查看. 由于后端只提供一个 RTSP 的直播协议, 所以所有的方案都是围绕着 RTSP 这个关键词. 当时时间很赶所以要自己慢慢研究是不可能了, 只能去找现成的库.

> 现目前用过三种方案, 都不完美.

### 整体思路
经过一波调研(google)之后, 知道浏览器对 RTSP 协议并不友好, 也就是说我们必须要自己转码再提供给浏览器使用, 找到的解决思路大概是:

1. 转码: [FFmpeg](https://www.ffmpeg.org/) 是一个老牌的转码工具, 非常强大
2. Node.js 用作中转站接收客户端发来的摄像机信息及控制 FFmpeg 推流
3. 最终客户端接收视频流

下面我试过的三种方案, 基本结构都如此只是推流的方式和客户端的接收方式有所不同.

### 准备

**安装 FFmpeg 转码工具**

- window 平台

1. [下载 FFmpeg](http://ffmpeg.zeranoe.com/builds/) 解压后应该是已经编译好的文件
2. 将解压好的文件放入 C 盘根目录(也可以自行放入其他盘符)下重命名为 ffmpeg(方便以后找)
3. 设置环境变量, 我的电脑 -> 属性 -> 高级系统设置 -> 环境变量 -> 系统变量 -> 新增, 路径选择刚刚 C 盘下的 ffmpeg文件夹中的 bin 文件夹
4. 注销或重启电脑让环境变量生效
5. 测试, 在 cmd 中输入 `ffmpeg -version`,  如果出现版本号之类的东西则成功.

- Mac 平台
Mac 下可以直接通过 `Homebrew` 安装最为简单.

1. 安装 `Homebrew`, 在终端中输入 `ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"`
2. 安装 FFmpeg, 直接在终端中输入 `brew install ffmpeg` 即可
3. 测试, 同样在终端中输入 `ffmpeg -version` 查看版本号

**安装 Node.js**
这个就不展开详细说了, 每个前端都有吧...

### 方案一: img 标签
当时想到的第一种方案也是最简单的方案, 是将视频流的每一帧转化为 base64 再通过动态替换 `<img>` 的 src 属性来达到预览的效果.中间用到了[rtsp-ffmpeg](https://github.com/agsh/rtsp-ffmpeg), 这个库的思路是通过 websocket 发送每一帧视频的 bytes 到客户端, 客户端可以通过 `<img>` 标签来展示.

示例: 

node 端
```js
const app = require('express')()
const server = require('http').Server(app)
const io = require('socket.io')(server)
const rtsp = require('rtsp-ffmpeg')

server.listen(8081, () => {
    console.log('server listening on 8081')
})

// uri 以海康摄像机的 rtsp 协议为例
let uri = 'rtps://admin:password@ip:port/h264/ch1/sub/av_stream'
let stream = new rtsp.FFMpeg({
    input: uri,
    resolution: '1080x720',
    quality: 3
})

stream.on('start', function () {
    console.log('stream')
})

stream.on('stop', function () {
    console.log('stream stopped')
})

io.on('connection', socket => {
    const pipeStream = data => {
        socket.emit('data', data)
    }
    stream.on('data', pipeStream)

    // 切换摄像机
    socket.on('URI', data => {
        console.log(data)
        uri = `rtsp://${data.userName}:${data.passWord}@${data.ip}:${data.port}/h264/ch1/sub/av_stream`
        stream.input = uri

        // 重启
        stream.restart()
    })

    socket.on('disconnect' () => {
        stream.removeListener('data', pipeStream)
    })
})
```

客户端
```html
<body>
    <img id='img'>
<script src='/socket.io/socket.io.js'></script>
<script>
	var io = io();
    let img = document.querySelector('#img')
	io.on('data', function(data) {
        let bytes = new Unit8Array(data)
        img.src = 'data:image/jpeg;base64,' + base64ArrayBuffer(bytes)
			
	})
    // byte 数组转 base64 (这段是在其他地方抄的)
	function base64ArrayBuffer(arrayBuffer) {
		var base64    = '';
		var encodings = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/';
		var bytes         = new Uint8Array(arrayBuffer);
		var byteLength    = bytes.byteLength;
		var byteRemainder = byteLength % 3;
		var mainLength    = byteLength - byteRemainder;
		var a, b, c, d;
		var chunk;
		// Main loop deals with bytes in chunks of 3
		for (var i = 0; i < mainLength; i = i + 3) {
			// Combine the three bytes into a single integer
			chunk = (bytes[i] << 16) | (bytes[i + 1] << 8) | bytes[i + 2];
			// Use bitmasks to extract 6-bit segments from the triplet
			a = (chunk & 16515072) >> 18; // 16515072 = (2^6 - 1) << 18
			b = (chunk & 258048)   >> 12; // 258048   = (2^6 - 1) << 12
			c = (chunk & 4032)     >>  6; // 4032     = (2^6 - 1) << 6
			d = chunk & 63;               // 63       = 2^6 - 1
			// Convert the raw binary segments to the appropriate ASCII encoding
			base64 += encodings[a] + encodings[b] + encodings[c] + encodings[d];
		}
		// Deal with the remaining bytes and padding
		if (byteRemainder == 1) {
			chunk = bytes[mainLength];
			a = (chunk & 252) >> 2; // 252 = (2^6 - 1) << 2
			// Set the 4 least significant bits to zero
			b = (chunk & 3)   << 4; // 3   = 2^2 - 1
			base64 += encodings[a] + encodings[b] + '==';
		} else if (byteRemainder == 2) {
			chunk = (bytes[mainLength] << 8) | bytes[mainLength + 1];
			a = (chunk & 64512) >> 10; // 64512 = (2^6 - 1) << 10
			b = (chunk & 1008)  >>  4; // 1008  = (2^6 - 1) << 4
			// Set the 2 least significant bits to zero
			c = (chunk & 15)    <<  2; // 15    = 2^4 - 1
			base64 += encodings[a] + encodings[b] + encodings[c] + '=';
		}
		return base64;
	}
</script>
</body>
```

这种通过 img 的方式暴露出的问题是需要在前端解码, 导致下一帧到来时上一帧的画面还没解码完成. 就会有花屏甚至画面只显示一半的问题和延迟较大且延迟会累积, 在控制台中你会看到疯狂刷从内存来的请求, 如果你想看看 http 请求可能会疯. 所以这种方式肯定不行

这个 `rtsp-ffmpeg` 还提供一种 canvas 的方式, 只是在客户端做一些修改:
```js
var io = io();
// 把之前的 img 标签换成 canvas
let canvas = document.querySelector('#canvas')
io.on('data', data => {
    var bytes = new Uint8Array(data)
					
    var blob = new Blob([bytes], {type: 'application/octet-binary'})
                    
    var url = URL.createObjectURL(blob)
                    
    var img = new Image
                    
    var ctx = canvas.getContext("2d")
        img.width = img.width * 0.5
        img.height = img.height * 0.5
        img.onload = function() {
            URL.revokeObjectURL(url)
            ctx.drawImage(img, 0, 0, 1080, 720)
        };    
    img.src = url
})
```

用 canvas 的方法虽然比 img 的效果好一点, 但是最终效果仍然是不尽人意. 图像很不稳定, 表现为一半画面一半绿屏, 如果视频中图像变换剧烈的话表现会更差, 所以这种方法也不太行. 其实在这中间我并没有做什么操作只是将这个 demo 集成在了 vue 中, 再加上多摄像机的切换和主流摄像机厂商的支持(因为每个摄像机厂商的 rtsp 协议的结构不一样)而已, 所以第一想法是能不能在解码这块找到更好解决办法, 于是又找到了另一个库 [jsmpeg](https://github.com/phoboslab/jsmpeg) 方案二就来了.


### 方案二: jsmpeg
这个库还算比较不错的了, 也是通过 websocket 来转发, 看官方的例子是在终端中启动 ffmpeg -> websocket -> 客户端通过 `jsmpeg.min.js` 解码在 canvas 中播放. 因为这里只是实现了播放, 在这个基础上我们还需要在脚本中自启 ffmpeg / 切换/ 重启, 然后又去找了一个基于 `jsmpeg` 的库 [node-rtsp-stream](https://github.com/kyriesent/node-rtsp-stream). 这个库只是做了一些封装让我们不用自己在终端中手动启用 ffmpeg, 在此之上我再加上重启就能满足现在的需求.

示例:

1. 改造 `node-rtsp-stream`

node-rtsp-stream/videoStream.js
```js
(function() {
    var Mpeg1Muxer, STREAM_MAGIC_BYTES, VideoStream, events, util, ws;

    ws = require('ws');

    util = require('util');

    events = require('events');

    Mpeg1Muxer = require('./mpeg1muxer');

    STREAM_MAGIC_BYTES = "jsmp";

    var child_process = require('child_process');

    VideoStream = function(options) {
        this.name = options.name;
        this.streamUrl = options.streamUrl;
        this.width = options.width;
        this.height = options.height;
        this.wsPort = options.wsPort;
        this.inputStreamStarted = false;
        this.stream = void 0;
        this.startMpeg1Stream();
        this.pipeStreamToSocketServer();
        return this;
    };

    util.inherits(VideoStream, events.EventEmitter);
    // 停止视频流
    VideoStream.prototype.stop = function () {
        if (this.mpeg1Muxer) {
            this.mpeg1Muxer.stream.stop()
        }
    }
    // 重启视频流
    VideoStream.prototype.restart = function() {
        if (this.mpeg1Muxer) {
            this.mpeg1Muxer.stream.stop()
            console.log('ffmpeg is restart')
            this.inputStreamStarted = false;
            this.stream = void 0;
            this.startMpeg1Stream();
            // 监听 ffmpeg 进程是否关闭
            this.mpeg1Muxer.on('ffmpegClose', function(code) {
                console.log('ffmpeg closed on ' + code)
            })
        }
    }

    VideoStream.prototype.startMpeg1Stream = function() {
        // 省略打开流的方法, 这部分没有做改动
    };

    VideoStream.prototype.pipeStreamToSocketServer = function() {
        // 将流塞给 socket, 同样也没改
    };

    VideoStream.prototype.onSocketConnect = function(socket) {
        var self, streamHeader;
        self = this;
        streamHeader = new Buffer(8);
        streamHeader.write(STREAM_MAGIC_BYTES);
        streamHeader.writeUInt16BE(this.width, 4);
        streamHeader.writeUInt16BE(this.height, 6);
        socket.send(streamHeader, {
            binary: true
        });
        console.log(("" + this.name + ": New WebSocket Connection (") + this.wsServer.clients.length + " total)");
        return socket.on("close", function(code, message) {
            return console.log(("" + this.name + ": Disconnected WebSocket (") + self.wsServer.clients.length + " total)");
        });
    };

    module.exports = VideoStream;

}).call(this);
```

node-rtsp-stream/videoStream.js
```js
(function() {
    var Mpeg1Muxer, child_process, events, util;

    child_process = require('child_process');

    util = require('util');

    events = require('events');

    Mpeg1Muxer = function(options) {
        var self;
        self = this;
        this.url = options.url;
        this.stream = child_process.spawn("ffmpeg", 
            [
                "-rtsp_transport",
                "tcp",
                "-i",
                this.url,
                '-s', 
                // 图像宽高
                `${options.width}x${options.height}`, 
                '-f', 
                'mpeg1video', 
                '-b:v', 
                '800k', 
                '-r', 
                '30', 
                '-'
            ], 
            {
                detached: false
            }
        );
        this.inputStreamStarted = true;
        this.stream.stdout.on('data', function(data) {
            return self.emit('mpeg1data', data);
        });
        this.stream.stderr.on('data', function(data) {
            return self.emit('ffmpegError', data);
        });
        // kill ffmpeg
        this.stream.stop = function() {
            // console.log(self.stream.pid)
            self.stream.stdin.pause();
            self.stream.kill()
            console.log('ffmpeg is be kill')
        };
        // 监听 ffmpeg 退出
        this.stream.on('exit', function(code) {
            return self.emit('ffmpegClose', code)
        })
        return this;
    };

    util.inherits(Mpeg1Muxer, events.EventEmitter);

    module.exports = Mpeg1Muxer;

}).call(this);
```

2. node 端使用

```js
const app = require('express')()
const server = require('http').Server(app)
const io = require('socket.io')(server)
// 引入改造后的 node-rtsp-stream
const Rtsp = require('./node-rtsp-stream')

server.listen(8081, () => {
    console.log('server listening on 8081')
})

// uri 以海康摄像机的 rtsp 协议为例
let uri = 'rtps://admin:password@ip:port/h264/ch1/sub/av_stream'
let stream = new Rtsp({
    name: 'rtsp_stream',
    streamUrl: uri,
    wsPort: 11111,
    width: 720,
    height: 405
})

stream.on('start', function () {
    console.log('stream')
})

stream.on('stop', function () {
    console.log('stream stopped')
})

io.on('connection', socket => {
    const pipeStream = data => {
        socket.emit('data', data)
    }
    stream.on('data', pipeStream)

    // 切换摄像机
    socket.on('URI', data => {
        console.log(data)
        uri = `rtsp://${data.userName}:${data.passWord}@${data.ip}:${data.port}/h264/ch1/sub/av_stream`
        stream.streamUrl = uri;
        // 重启
        stream.restart()
    })

    socket.on('disconnect' () => {
        stream.removeListener('data', pipeStream)
    })
})
```

3. 客户端

```html
<canvas id='can'></canvas>
<script src='jsmpeg.min.js'></script>
<script>
    let canvas = document.querySelector('#can')
    let ws = new WebSocket('ws://127.0.0.1:11111')
    let player = new jsmpeg(ws, {
        canvas: canvas,
        autoplay: true
    })
</script>
```

这个方案其实使用了很久一直都没发现问题, 是在一路摄像机安置在天桥附近人流量剧增, 与这个视频预览同一页面还有一个人脸实时抓拍的即时消息推送的功能, 导致在20 - 30分钟浏览器直接假死或者崩溃.(然后这个方案又凉了😂)

### 方案三: FFmpeg + Nginx + video.js
方案三下次写~



Created on 2017/7/26 by Cara
